Este capítulo se centra en la fase de evaluación de los modelos entrenados y correspondiente con la fase de evaluación de la metodología CRISP-DM. Se describe el conjunto de datos de prueba, el proceso de evaluación, la presentación de los resultados de las métricas y el análisis de las fortalezas y debilidades de los modelos.

\section{Conjunto de datos de prueba}
Para obtener el conjunto de datos para el entrenamiento de los modelos y el conjunto de datos de prueba, se ha de dividir el conjunto total de los datos, una vez que estos han sido preparados como siguiendo los pasos que se comentan en la Sección \ref{sec.prep-datos} \nameref{sec.prep-datos}. 


Al dividir el conjunto de datos, es crucial aplicar estratificación. Como se menciona en capítulos previos, esta técnica implica segmentar los datos de forma que se mantenga la misma distribución de clases en cada subconjunto. Esto resulta especialmente útil cuando las clases están desbalanceadas, ya que garantiza que todos los subconjuntos cuenten con una representación proporcional de cada clase, lo que mejora la precisión del modelo y minimiza los sesgos. Dado el desbalanceo observado en los datos de este trabajo, es esencial realizar una estratificación en cada división de los datos para evitar que algunas particiones contengan únicamente datos de una clase.


La división del conjunto de datos suele ser de en un 80\% para entrenamiento y un 20\% para evaluación, esta división se fundamenta en la necesidad de proporcionar suficiente cantidad de datos para que el modelo aprenda de manera efectiva, mientras se mantiene un conjunto de datos no utilizado en el entrenamiento para evaluar su rendimiento generalizando. La proporción del 80\% se considera adecuada para capturar patrones significativos en el entrenamiento sin comprometer la capacidad de evaluar el modelo en datos no vistos, lo que permite estimar su desempeño en situaciones realistas. Esta práctica también ayuda a evitar el sobreajuste, garantizando que los resultados del modelo no dependa en exclusiva de los datos utilizados en el entrenamiento \cite{bishop2006pattern}.

Para realizar la división, se utiliza la función \texttt{train\_test\_split} de la biblioteca \texttt{sklearn. model\_selection}. Esta función recibe el conjunto de los atributos y de las etiquetas de todo el \textit{dataset} utilizado, una vez que sus datos han sido preparados. Además, esta función recibe el porcentaje de los datos que se desea reservar para la evaluación o la fase de test, como se comenta en el párrafo anterior, en este trabajo el $0.2$ sobre 1 de los datos se destinan a evaluar los modelos entrenados. Finalmente, se especifica una semilla para que los datos se organicen de manera aleatoria y se especifica que se desea estratificar siguiendo el conjunto de las etiquetas.

Una vez divididos los datos, se normalizan los datos de evaluación, se convierten a tensores el conjunto de los atributos de pruebas y el conjunto de las etiquetas y se crea con estos tensores la instancia de la clase \texttt{DatasetTFG} que se utilizará para evaluar los modelos.

\section{Proceso de evaluación}
En el proceos de búsqueda de las configuraciones de hiperparámetros de los modelos con las que estos convergen mejor hacia una solución más generalizada, se ha utilizado la validación cruzada como se comenta en la Sección \ref{subsec:conjdatent}. La validación cruzada se utiliza para encontrar los mejores hiperparámetros de un modelo debido a su capacidad para proporcionar una evaluación más robusta y confiable del rendimiento del modelo. Este método divide el conjunto de datos en varios subconjuntos, realizando múltiples entrenamientos y evaluaciones, lo que permite reducir el riesgo de sobreajuste a un subconjunto específico. Además, la validación cruzada maximiza el uso de los datos disponibles, lo que resulta especialmente útil cuando los datos son limitados. 

Una vez que se han encontrado los hiperparámetros óptimos, se utiliza todo el conjunto de datos de entrenamiento, es decir, el 80\% del conjunto de datos para entrenar los modelos finales. Esto se debe a que, al haber ajustado previamente los hiperparámetros, se considera que los modelos se encuentran en sus configuraciones más eficientes, lo cual maximiza sus capacidades de generalización al aprender de la mayor cantidad de datos posible. De este modo, se obtienen unos modelos más robusto antes de realizar la evaluación final sobre un conjunto de prueba independiente que no ha sido utilizado en el proceso de entrenamiento \cite{hastie2009elements}.

El procesos de evaluación consiste en proporcionar a los modelos entrenados con las configuraciones comentadas en los párrafos anteriores, los datos de evaluación que no han visto durante la fase de entrenamiento. Durante este proceso se recogen los resultados que se obtienen en función de la matriz de confusión correspondiente a cada modelo para posteriormente obtener las métricas con las que comparar el desempeño de los modelos.

\section{Resultados de las métricas en el proceso de evaluación}
Para comparar los resultados obtenidos en la fase de evaluación de las cinco mejores configuraciones de hiperparámetros de cada arquitectura de cada modelo, se utilizan las mismas métricas comentadas en las Secciones \ref{sec.metricas-bin} \nameref{sec.metricas-bin} y \ref{sec:metricas-mul} \nameref{sec:metricas-mul} correspondientemente.

Con el objetivo de que la interpretación de los datos sea más sencilla, se ha añadido a las siguientes figuras una columna con la posición del \textit{ranking} que ocupó cada configuración en la fase anterior.


\subsection{Resultados del modelo de clasificación binaria}
La métrica utilizada para establecer el orden en los siguientes \textit{rankings} de configuraciones para los modelos de clasificación binaria es la misma empleada durante la fase previa de búsqueda de las mejores configuraciones de hiperparámetros: el \textit{Recall}.

\subsubsection{MCB25: Modelo de clasifcación binaria con un tamaño de capa oculta igual a la mitad del número de atributos de entrada que recibe el modelo}
En la Tabla \ref{fig:EVALMCB25}, se muestran los resultados obtenidos durante las evaluaciones de las cinco configuraciones de hiperparámetros con mejor desempeño durante la fase de búsqueda mencionados en la Figura \ref{fig:BINhs25}. Corresponden con las mejores configuraciones para la arquitectura del modelo de clasificación binaria que posee un tamaño de capa oculta de 25 neuronas.

\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 3º-MCB25 & 2º-MCB25 & 1º-MCB25 & 5º-MCB25 & 4º-MCB25\\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}20000 & \cellcolor[HTML]{66ffa8}10000 & \cellcolor[HTML]{66ffa8}15000 & \cellcolor[HTML]{66ffa8}2000 & \cellcolor[HTML]{66ffa8}20000 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.01 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}30 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}20 \\
\cellcolor[HTML]{E0FFFF}test\_recall & 0.998749 & 0.998640 & 0.998586 & 0.998422 & 0.998368 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.999831 & 0.999813 & 0.999824 & 0.999826 & 0.999826 \\
\cellcolor[HTML]{E0FFFF}test\_f1 & 0.997934 & 0.997717 & 0.997853 & 0.997879 & 0.997879 \\
\cellcolor[HTML]{E0FFFF}test\_f2 & 0.998423 & 0.998271 & 0.998292 & 0.998205 & 0.998172 \\
\cellcolor[HTML]{E0FFFF}test\_precision & 0.997121 & 0.996796 & 0.997121 & 0.997337 & 0.997391 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc & 0.999765 & 0.999772 & 0.999841 & 0.999818 & 0.999899 \\
\cellcolor[HTML]{E0FFFF}test\_specificity & 0.999877 & 0.999863 & 0.999877 & 0.999886 & 0.999888 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de  clasificación binaria con \textit{n/2} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCB25}
\end{table}


Los valores de la métrica \textit{Recall} obtenidos en las evaluaciones del modelo MCB25, son muy altos para todas las configuraciones y la diferencia entre sus valores es del orden de $1*10^{-4}$. Estas diferencias pueden deberse a circunstancias no controlables como el estado en el que se encontraba la máquina cuando se realizó la evaluación de los modelos o los pesos aleatorios iniciales que se eligieron en esa ejecución de los test.

La matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 3º MCB25 durante su evaluación es la que se muestra en la Figura \ref{fig:MC_EVAL_MCB25}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCB25.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 3º MCB25 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCB25}
\end{figure}


\subsubsection{MCB49: Modelo de clasifcación binaria con un tamaño de capa oculta igual al número de atributos de entrada que recibe el modelo}
En la Tabla \ref{fig:EVALMCB49} se presentan los resultados obtenidos durante las evaluaciones de las cinco configuraciones de hiperparámetros con mejor desempeño, seleccionadas en la fase de búsqueda en la Figura \ref{fig:BINhs49} para la arquitectura del modelo de clasificación binaria que cuenta con una capa oculta de 49 neuronas.



\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 2º-MCB49 & 1º-MCB49 & 5º-MCB49 & 3º-MCB49 & 4º-MCB49 \\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}10000 & \cellcolor[HTML]{66ffa8}20000 & \cellcolor[HTML]{66ffa8}2000 & \cellcolor[HTML]{66ffa8}15000 & \cellcolor[HTML]{66ffa8}2000 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.0001 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.001 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}30 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}30 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}10 \\
\cellcolor[HTML]{E0FFFF}test\_recall & 0.998640 & 0.998640 & 0.998477 & 0.998477 & 0.998259 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.999826 & 0.999835 & 0.999799 & 0.999835 & 0.999824 \\
\cellcolor[HTML]{E0FFFF}test\_f1 & 0.997880 & 0.997988 & 0.997554 & 0.997988 & 0.997852 \\
\cellcolor[HTML]{E0FFFF}test\_f2 & 0.998336 & 0.998379 & 0.998107 & 0.998281 & 0.998096 \\
\cellcolor[HTML]{E0FFFF}test\_precision & 0.997121 & 0.997338 & 0.996633 & 0.997500 & 0.997445 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc & 0.999807 & 0.999843 & 0.999809 & 0.999898 & 0.999863 \\
\cellcolor[HTML]{E0FFFF}test\_specificity & 0.999877 & 0.999886 & 0.999856 & 0.999893 & 0.999891 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de clasificación binaria con \textit{n} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCB49}
\end{table}



Los valores de la métrica \textit{Recall} obtenidos durante las evaluaciones del modelo MCB49 son consistentemente altos para todas las configuraciones, y las diferencias entre ellos se encuentran en el orden de magnitud de $1*10^{-4}$. Estas variaciones podrían atribuirse a factores no controlables, como el estado del sistema al momento de la evaluación o la aleatoriedad en la inicialización de los pesos durante la ejecución de las pruebas.

La matriz de confusión correspondiente a la mejor configuración de hiperparámetros obtenida en el 2º MCB49 durante su evaluación se presenta en la Figura \ref{fig:MC_EVAL_MCB49}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCB49.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 2º MCB49 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCB49}
\end{figure}



\subsubsection{MCB98: Modelo de clasifcación binaria con un tamaño de capa oculta igual al doble del número de atributos de entrada que recibe el modelo}
La Tabla \ref{fig:EVALMCB98} muestra los resultados obtenidos en las evaluaciones correspondientes a las cinco configuraciones de hiperparámetros que presentaron el mejor desempeño durante la fase de búsqueda mostradas en al Figura \ref{fig:BINhs98}, aplicadas a la arquitectura del modelo de clasificación binaria con una capa oculta de 98 neuronas.
\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 3º-MCB98 & 5º-MCB98 & 1º-MCB98 & 4º-MCB98 & 2º-MCB98 \\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}15000 & \cellcolor[HTML]{66ffa8}10000 & \cellcolor[HTML]{66ffa8}20000 & \cellcolor[HTML]{66ffa8}15000 & \cellcolor[HTML]{66ffa8}10000 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.001 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}30 & \cellcolor[HTML]{b1bafb}20 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}10 & \cellcolor[HTML]{b1bafb}30 \\
\cellcolor[HTML]{E0FFFF}test\_recall & 0.998749 & 0.998749 & 0.998694 & 0.998477 & 0.998096 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.999828 & 0.999822 & 0.999842 & 0.999833 & 0.999817 \\
\cellcolor[HTML]{E0FFFF}test\_f1 & 0.997907 & 0.997826 & 0.998070 & 0.997961 & 0.997770 \\
\cellcolor[HTML]{E0FFFF}test\_f2 & 0.998412 & 0.998379 & 0.998444 & 0.998270 & 0.997966 \\
\cellcolor[HTML]{E0FFFF}test\_precision & 0.997067 & 0.996905 & 0.997446 & 0.997446 & 0.997445 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc & 0.999783 & 0.999770 & 0.999899 & 0.999899 & 0.999868 \\
\cellcolor[HTML]{E0FFFF}test\_specificity & 0.999874 & 0.999868 & 0.999891 & 0.999891 & 0.999891 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de clasificación binaria con \textit{2n} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCB98}
\end{table}

En las evaluaciones del modelo MCB98, los valores obtenidos para la métrica \textit{Recall} fueron elevados en todas las configuraciones, con diferencias del orden de $1*10^{-4}$. Estas pequeñas variaciones pueden explicarse por factores no controlables, como el estado del sistema en el momento de la evaluación o la inicialización aleatoria de los pesos durante la ejecución de las pruebas.


La matriz de confusión correspondiente a la mejor configuración de hiperparámetros obtenida en el 3º MCB98 durante su evaluación se presenta en la Figura \ref{fig:MC_EVAL_MCB98}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCB98.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 3º MCB98 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCB98}
\end{figure}




\subsection{Resultados del modelo de clasificación multiclase}
Para determinar el orden de los \textit{rankings} presentados a continuación, se emplea la misma métrica utilizada en la fase de búsqueda de configuraciones de hiperparámetros para los modelos de clasificación multiclase: el \textit{F1-weighted}.

\subsubsection{MCM25: Modelo de clasifcación multiclase con un tamaño de capa oculta igual a la mitad del número de atributos de entrada que recibe el modelo}

En la Tabla \ref{fig:EVALMCM25} se presentan los resultados obtenidos durante las evaluaciones de las cinco configuraciones de hiperparámetros con mejores métricas, identificadas durante la fase de búsqueda de hiperparámetros para la arquitectura del modelo de clasificación multiclase que cuenta con una capa oculta de 25 neuronas.

\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 3º-MCM25 & 2º-MCM25 & 1º-MCM25 & 4º-MCM25 & 5º-MCM25 \\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}128 & \cellcolor[HTML]{66ffa8}512 & \cellcolor[HTML]{66ffa8}64 & \cellcolor[HTML]{66ffa8}256 & \cellcolor[HTML]{66ffa8}128 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}100 & \cellcolor[HTML]{b1bafb}100 & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}50 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_weighted & 0.538465 & 0.529706 & 0.491948 & 0.490342 & 0.435692 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.519667 & 0.498341 & 0.463631 & 0.458354 & 0.406536 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_macro & 0.371639 & 0.340072 & 0.339593 & 0.333974 & 0.305804 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_macro & 0.415200 & 0.384902 & 0.376401 & 0.374790 & 0.354471 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_weighted & 0.681380 & 0.670107 & 0.642648 & 0.646698 & 0.640704 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_macro & 0.356826 & 0.325361 & 0.327492 & 0.320251 & 0.293147 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_weighted & 0.568975 & 0.553186 & 0.550136 & 0.550342 & 0.534025 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovo & 0.878231 & 0.871589 & 0.871532 & 0.877010 & 0.870398 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovr & 0.875697 & 0.868443 & 0.870934 & 0.874640 & 0.867136 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de clasificación multiclase con \textit{n/2} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCM25}
\end{table}

La Tabla \ref{fig:EVALMCM25} anterior evidencia una diferencia en los valores de la métrica de comparación considerablemente mayor que la observada para las mismas configuraciones durante la fase de búsqueda de hiperparámetros. En los cinco mejores modelos representados en la figura, las diferencias en la métrica \textit{F1-weighted} durante la fase de búsqueda se encuentran en el orden de $1*10^{-2}$, mientras que en la fase de evaluación alcanzan un orden de $1*10^{-1}$, lo que indica una discrepancias con respecto a los resultados observados en la búsqueda de hiperparáemtros de la fase de modelado.

La matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 3º MCM25 durante su evaluación, es la que se muestra en la Figura \ref{fig:MC_EVAL_MCM25}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCM25.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida con en el 3º MCM25 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCM25}
\end{figure}

Dado que los datos empleados para entrenar el modelo de clasificación multiclase presentan un elevado desbalance entre clases, se recurre a la funcionalidad de normalización de matrices de confusión de \texttt{wandb} para generar una representación visual más informativa que la mostrada en la Figura \ref{fig:MC_EVAL_MCM25}. Esta técnica permite observar de forma más clara el comportamiento del modelo en cada clase, independientemente de su frecuencia en los datos, tal y como se puede apreciar en la Figura \ref{fig:MCNorm_EVAL_MCM25}. Al comparar ambas figuras, destaca la alto porcentaje de aciertos en la clase 0 y 8 en la Figura \ref{fig:MCNorm_EVAL_MCM25} y los resultados menos precisos para la clase 3.

La normalización en \texttt{wandb} convierte los conteos absolutos de la matriz de confusión en proporciones por clase real, lo que facilita la comparación del rendimiento del modelo entre clases desbalanceadas.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{./img/evaluacion/matrices_confusion/MCNorm_EVAL_MCM25.pdf}
    \caption{Matriz de confusión normalizada de la mejor configuración de hiperparámetros obtenida en el 3º MCM25 durante la fase de evaluación.}
    \label{fig:MCNorm_EVAL_MCM25}
\end{figure}



\subsubsection{MCB49: Modelo de clasifcación multiclase con un tamaño de capa oculta igual al número de atributos de entrada que recibe el modelo}
La Tabla \ref{fig:EVALMCM49} presenta los resultados de las evaluaciones realizadas sobre las cinco configuraciones de hiperparámetros con mejores métricas, seleccionadas durante la fase de búsqueda aplicada a la arquitectura del modelo de clasificación multiclase con una capa oculta compuesta por 49 neuronas.


\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 5º-MCM49 & 4º-MCM49 & 3º-MCM49 & 2º-MCM49 & 1º-MCM49 \\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}256 & \cellcolor[HTML]{66ffa8}64 & \cellcolor[HTML]{66ffa8}128 & \cellcolor[HTML]{66ffa8}128 & \cellcolor[HTML]{66ffa8}256 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}50 & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}100 & \cellcolor[HTML]{b1bafb}50 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_weighted & 0.516647 & 0.501065 & 0.498233 & 0.467576 & 0.436878 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.486589 & 0.461617 & 0.452423 & 0.429247 & 0.416081 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_macro & 0.368803 & 0.325784 & 0.339188 & 0.316954 & 0.327882 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_macro & 0.348930 & 0.326530 & 0.338391 & 0.327875 & 0.331214 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_weighted & 0.657655 & 0.648645 & 0.671855 & 0.656385 & 0.651054 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_macro & 0.560934 & 0.555375 & 0.572878 & 0.552602 & 0.534408 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_weighted & 0.486589 & 0.461617 & 0.452423 & 0.429247 & 0.416081 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovo & 0.883130 & 0.877907 & 0.887773 & 0.883284 & 0.875257 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovr & 0.850867 & 0.848678 & 0.859088 & 0.847522 & 0.841436 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de clasificación multiclase con \textit{n} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCM49}
\end{table}

Al analizar los resultados obtenidos para esta arquitectura, destaca más allá del bajo rendimiento reflejado por la métrica \textit{F1-weighted}, el hecho de que el orden de las configuraciones se ha invertido respecto a lo observado en la fase de búsqueda. Las posibles causas de este comportamiento se detallan en la Sección \ref{sec:analEVAL}.

La matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 5º MCM49 durante su evaluación, es la que se muestra en la Figura \ref{fig:MC_EVAL_MCM49}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCM49.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida con en el 5º MCM49 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCM49}
\end{figure}

Dado el elevado desbalance entre clases en los datos utilizados para entrenar el modelo de clasificación multiclase, se emplea la funcionalidad de normalización de matrices de confusión de \texttt{wandb} para generar una representación visual más informativa que la presentada en la Figura \ref{fig:MC_EVAL_MCM49}. Esta técnica facilita la observación más clara del comportamiento del modelo en cada clase, independientemente de su frecuencia en los datos, como se puede observar en la Figura \ref{fig:MCNorm_EVAL_MCM49}. Comparando la Figura \ref{fig:MCNorm_EVAL_MCM25} con la figura de los datos normalizados del MCM49, se observa que como consecuencia del cambio de arquitectura, las prácticamente las predicciones para todas las clases han empeorado, a excepción de la clase 5 que ha obtenido mejores resultados que en el MCM25.

La normalización en \texttt{wandb} convierte los conteos absolutos de la matriz de confusión en proporciones por clase real, lo que facilita la comparación del rendimiento del modelo entre clases desbalanceadas.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{./img/evaluacion/matrices_confusion/MCNorm_EVAL_MCM49.pdf}
    \caption{Matriz de confusión normalizada de la mejor configuración de hiperparámetros obtenida en el 5º MCM49 durante la fase de evaluación.}
    \label{fig:MCNorm_EVAL_MCM49}
\end{figure}




\subsubsection{MCB98: Modelo de clasifcación multiclase con un tamaño de capa oculta igual al doble del número de atributos de entrada que recibe el modelo}
En la Tabla \ref{fig:EVALMCM98} se ilustran los resultados obtenidos durante las evaluaciones correspondientes a las cinco configuraciones de hiperparámetros con mejores métricas, seleccionadas en la etapa de búsqueda de configuraciones para la arquitectura del modelo de clasificación multiclase con una capa oculta de 98 neuronas..

\begin{table}[H]
\begin{tabular}{|>{\columncolor[HTML]{E0FFFF}}l|c|c|c|c|c|}
\hline
Posicion\_EXP & 4º-MCM98 & 2º-MCM98 & 1º-MCM98 & 3º-MCM98 & 5º-MCM98 \\
\hline
\cellcolor[HTML]{E0FFFF}batch\_size & \cellcolor[HTML]{66ffa8}64 & \cellcolor[HTML]{66ffa8}256 & \cellcolor[HTML]{66ffa8}256 & \cellcolor[HTML]{66ffa8}512 & \cellcolor[HTML]{66ffa8}256 \\
\cellcolor[HTML]{E0FFFF}learning\_rate & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.001 & \cellcolor[HTML]{f99595}0.01 & \cellcolor[HTML]{f99595}0.001 \\
\cellcolor[HTML]{E0FFFF}epochs & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}80 & \cellcolor[HTML]{b1bafb}100 & \cellcolor[HTML]{b1bafb}100 & \cellcolor[HTML]{b1bafb}50 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_weighted & 0.568500 & 0.509088 & 0.506429 & 0.492392 & 0.465032 \\
\cellcolor[HTML]{E0FFFF}test\_accuracy & 0.545944 & 0.456177 & 0.447037 & 0.460094 & 0.424786 \\
\cellcolor[HTML]{E0FFFF}test\_f1\_macro & 0.375845 & 0.345703 & 0.339473 & 0.359955 & 0.315588 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_macro & 0.365704 & 0.355874 & 0.368615 & 0.348133 & 0.324259 \\
\cellcolor[HTML]{E0FFFF}test\_precision\_weighted & 0.663088 & 0.690381 & 0.700087 & 0.646679 & 0.658504 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_macro & 0.574354 & 0.583812 & 0.578126 & 0.573286 & 0.567694 \\
\cellcolor[HTML]{E0FFFF}test\_recall\_weighted & 0.545944 & 0.456177 & 0.447037 & 0.460094 & 0.424786 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovo & 0.888441 & 0.890550 & 0.888079 & 0.879829 & 0.884775 \\
\cellcolor[HTML]{E0FFFF}test\_roc\_auc\_ovr & 0.865108 & 0.857470 & 0.859871 & 0.858953 & 0.847066 \\
\hline
\end{tabular}
    \caption{Resultados de la evaluación del modelo de clasificación multiclase con \textit{2n} neuronas en la capa oculta siendo \textit{n} el número de atributos de entrada.}
    \label{fig:EVALMCM98}
\end{table}

Los resultados obtenidos durante la fase de evaluación de esta arquitectura fueron significativamente inferiores a los alcanzados en la fase de búsqueda. Por ejemplo, en la quinta mejor configuración de hiperparámetros, la diferencia entre los resultados experimentales y los obtenidos en la evaluación es del orden de $1*10^{-1}$. Esta diferencia implica una reducción del 10\% en la precisión, o bien, un mayor número de errores en las clases con menor cantidad de muestras en comparación con la fase anterior.


La matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 4º MCM98 durante su evaluación, es la que se muestra en la Figura \ref{fig:MC_EVAL_MCM98}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./img/evaluacion/matrices_confusion/MC_EVAL_MCM98.png}
    \caption{Matriz de confusión de la mejor configuración de hiperparámetros obtenida en el 4º MCM98 durante la fase de evaluación.}
    \label{fig:MC_EVAL_MCM98}
\end{figure}

Debido al desbalanceo significativo entre las clases del conjunto de datos utilizados para entrenar el modelo de clasificación multiclase, se opta por utilizar la funcionalidad de normalización de matrices de confusión de \texttt{wandb}. Esta técnica permite generar una representación visual más clara que la mostrada en la Figura \ref{fig:MC_EVAL_MCM98}, facilitando así un análisis más preciso del comportamiento del modelo en cada clase, sin que este dependa de la frecuencia de las clases en los datos. Al comparar la Figura \ref{fig:MCNorm_EVAL_MCM98}, que corresponde con la versión normalizada del MCM98,  con las Figuras \ref{fig:MCNorm_EVAL_MCM49} y \ref{fig:MCNorm_EVAL_MCM25}, se percibe una mejora generalizada en la predicción de todas las clases. La única excepción es la clase 5, donde la arquitectura del MCM98 presenta peores resultados en comparación con el MCM25.

La normalización en \texttt{wandb} transforma los conteos absolutos de la matriz de confusión en proporciones por clase real, lo que simplifica la comparación del rendimiento del modelo, especialmente en situaciones con clases muy desbalanceadas.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{./img/evaluacion/matrices_confusion/MCNorm_EVAL_MCM98.pdf}
    \caption{Matriz de confusión normalizada de la mejor configuración de hiperparámetros obtenida en el MCM98 durante la fase de evaluación.}
    \label{fig:MCNorm_EVAL_MCM98}
\end{figure}




\section{Análisis de los resultados obtenidos} \label{sec:analEVAL}
\subsection{Modelo de clasificación binaria}

Los resultados obtenidos durante la fase de búsqueda de las mejores configuraciones de hiperparámetros empleando validación cruzada \textit{k-fold} con estratificación muestran valores de \textit{Recall} consistentemente altos, todos por encima de $0{.}9985$, como se detalla en la Figura \ref{fig:BINtop5}. Este rendimiento indica una capacidad del modelo para identificar correctamente la clase mayoritaria de forma fiable y robusta en distintos subconjuntos de datos, lo cual respalda la estabilidad de las configuraciones seleccionadas durante esta fase de optimización \cite{bergstra2012random}.

Sin embargo, al aplicar estas mismas configuraciones en la fase de evaluación sobre un conjunto independiente (Figura \ref{fig:top5EVALMCB}), se observa una inversión parcial en el orden del rendimiento de las configuraciones. Algunas de las configuraciones con las mejores métricas en la búsqueda no mantienen su posición, mientras que otras ascienden en el \textit{ranking}. Este comportamiento puede atribuirse a pequeñas variaciones aleatorias en los datos o a la sensibilidad del modelo frente a distribuciones ligeramente diferentes, aun cuando estas diferencias se hayan mitigado mediante estratificación \cite{reimers2017optimal}.

A pesar de que las diferencias absolutas entre los valores de \textit{Recall} en ambas fases son reducidas (del orden de $1*10^{-4}$ a $1*10^{-3}$), su impacto puede ser relevante en tareas de clasificación binaria crítica, como la detección de conexiones maliciosas, donde incluso mínimas variaciones pueden traducirse en decisiones erróneas. El empeoramiento de algunas de las métricas puede deberse a factores como la inicialización aleatoria de pesos o el estado del sistema durante la inferencia, más que a un verdadero sobreajuste, dado que el proceso de validación cruzada ya controla adecuadamente este riesgo \cite{goodfellow2016deep}.

Asimismo, el análisis muestra que distintas combinaciones de \texttt{batch\_size}, \texttt{epochs}, \texttt{hidden \_size} y \texttt{learning\_rate} conducen a valores de \textit{Recall} muy próximos en evaluación. Esta convergencia en el rendimiento es coherente con estudios que sugieren que múltiples configuraciones en regiones planas del espacio de pérdida pueden llevar a modelos igualmente eficaces, especialmente en arquitecturas con un número de neuronal elevado como las utilizadas \cite{bouthillier2021sloppy}.

La observación de que varias configuraciones producen valores prácticamente idénticos de \textit{Recall} en la evaluación sugiere la presencia de una región de estabilidad en el espacio de soluciones. Sin embargo, el hecho de que estas configuraciones no coincidan con las mejor posicionadas en la búsqueda indica que, aunque la validación cruzada estratificada proporciona una estimación robusta, puede no capturar completamente la variabilidad inherente del conjunto de evaluación, especialmente si este presenta ligeras desviaciones de la distribución global \cite{recht2019imagenet}.

Los resultados reflejan un comportamiento coherente con lo esperado para modelos que han sido correctamente validados. Las diferencias encontradas entre fases no parecen ser estadísticamente significativas, pero sí lo suficientemente marcadas como para sugerir la conveniencia de utilizar estrategias complementarias de evaluación en futuros experimentos, como pruebas de sensibilidad o análisis de varianza.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{./img/evaluacion/resultados/top5EVALMCB.pdf}
    \caption{Mejores cinco modelos en la fase de evaluación del modelo de clasificación binaria.}
    \label{fig:top5EVALMCB}
\end{figure}

\subsection{Modelo de clasificación multiclase}

Los resultados obtenidos durante la fase de búsqueda de hiperparámetros del modelo de clasificación multiclase (MCM), reflejados en la Figura \ref{fig:MULtop10}, indican valores moderados en las métricas utilizadas. En particular, el valor promedio de \textit{F1-weighted} se sitúa en torno a $0{.}57$, con ligeras variaciones entre las distintas configuraciones probadas. Este nivel de desempeño es coherente con la naturaleza desbalanceada del conjunto de datos, ya que el predominio de algunas clases afecta negativamente al promedio ponderado de precisión y \textit{Recall} \cite{he2009learning}.

Las métricas \textit{F1-macro} y \textit{Precision-macro} presentan valores sustancialmente más bajos que sus contrapartes ponderadas, lo que confirma que el modelo no logra un rendimiento equilibrado entre clases minoritarias y mayoritarias. Esta brecha sugiere que las clases menos representadas no son detectadas con suficiente eficacia, un fenómeno frecuente en escenarios de desbalance como el que se presenta en este trabajo, incluso al aplicar validación cruzada estratificada \cite{johnson2019survey}.

Al observar los resultados de la fase de evaluación (Figura \ref{fig:top5EVALMCM}), se constata que la métrica \textit{F1-weighted} no mejora significativamente respecto a la fase de búsqueda. De hecho, se observan valores incluso más bajos en algunas configuraciones, con un máximo de aproximadamente $0{.}568$ y un mínimo cercano a $0{.}509$. Este comportamiento sugiere que las configuraciones seleccionadas no generalizan adecuadamente al conjunto completo, a pesar de haber sido validadas mediante \textit{k-folds} \cite{reimers2017optimal}.

El análisis también muestra que el orden de las configuraciones en términos de rendimiento cambia entre ambas fases. Configuraciones que ocupaban posiciones intermedias o bajas durante la búsqueda escalan posiciones en la evaluación y viceversa. Esto podría estar relacionado con la distribución específica de las clases en el conjunto completo usado para la evaluación, el cual puede no coincidir exactamente con la distribución estratificada de los pliegues empleados durante la validación por circunstancias no controlables \cite{buda2018systematic}.

La pérdida de rendimiento observada puede explicarse también por el hecho de que, al entrenar con el conjunto completo en la evaluación, se pierde la ventaja del promedio sobre múltiples particiones que ofrece la validación cruzada. Esta situación puede inducir mayor varianza en los resultados y resaltar la sensibilidad del modelo a configuraciones particulares del entrenamiento \cite{dietterich1998approx}.

Por otra parte, el hecho de que el mejor resultado de \textit{F1-weighted} en evaluación ($0{.}568$) sea comparable al mejor valor obtenido en la búsqueda sugiere que el modelo alcanza un rendimiento máximo limitado por la naturaleza del problema. La estructura altamente desbalanceada del conjunto impone un techo al rendimiento global del modelo \cite{japkowicz2002class}.

A pesar de que el modelo 4º-MCM98 presenta una precisión global moderada (test\_accuracy $\approx$ 54.6 \%), sus valores de AUC, tanto en el enfoque \textit{One-vs-Rest} (0.8651) como en \textit{One-vs-One} (0.8884), indican una buena capacidad para distinguir entre las diferentes clases. Esto sugiere que el modelo, aunque no siempre acierta en la clase exacta, logra asignar puntuaciones de probabilidad adecuadas que reflejan correctamente la proximidad a la clase verdadera.


El modelo de clasificación multiclase presenta un rendimiento aceptable dadas las condiciones desbalanceadas del problema, pero revela claras limitaciones en la detección equilibrada de clases. Las discrepancias entre búsqueda y evaluación reflejan la dificultad del modelo para mantener un rendimiento robusto al exponerse a la totalidad del conjunto, y sugieren la necesidad de introducir nuevas estrategias no probadas en la Sección \ref{subsec:MCMdescart} \nameref{subsec:MCMdescart} orientadas al tratamiento explícito del desbalanceo de clases en futuras fases del desarrollo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{./img/evaluacion/resultados/top5EVALMCM.pdf}
    \caption{Mejores cinco modelos en la fase de evaluación del modelo de clasificación multiclase.}
    \label{fig:top5EVALMCM}
\end{figure}

\section{Comparación de los resultados obtenidos con proyectos similares}

A continuación, se realiza una comparación entre los modelos propuestos en el presente trabajo y los desarrollados por \textit{Sarhan et al.}~\cite{sarhan2020netflow}, ambos aplicados a la detección de ataques en redes informáticas utilizando versiones del conjunto de datos \texttt{NF-UNSW-NB15-v3}.

\begin{itemize}
	\item Para el modelo de clasificación binaria, el respresentante de este trabajo será el que mejores resultados ha obtenido durante la fase de evaluación, el 3º-MCB98.
	\item Para el modelo de clasificación multiclase,el respresentante de este trabajo será el que mejores resultados ha obtenido durante la fase de evaluación, el 4º-MCM98. 
\end{itemize}


\subsection{Comparación de los modelos de clasificación binaria}

En la Tabla \ref{tab:compbin}, el modelo 3º-MCB98 evidencia una mejora sustancial en todas las métricas comparado con el modelo de \textit{Sarhan et al.}, destacando un aumento de $0.1479$ en el \textit{F1-Score} y más de cinco puntos porcentuales en el \textit{AUC}. Estas mejoras pueden atribuirse al uso de técnicas avanzadas de entrenamiento, ajuste de hiperparámetros y optimización de características.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Modelo} & \textbf{\textit{Accuracy}} & \textbf{\textit{AUC}} & \textbf{\textit{F1-Score}} & \textbf{\textit{Recall}} & \textbf{\textit{Precision}} & \textbf{\textit{Specificity}} \\
\hline
\textit{Sarhan et al.} & 98.62\% & 0.9485 & 0.85 & -- & -- & -- \\
3º-MCB98 & 99.98\% & 0.9998 & 0.9979 & 0.9987 & 0.9971 & 0.9999 \\
\hline
\end{tabular}
\caption{Comparación de modelos de clasificación binaria.}
\label{tab:compbin}
\end{table}

\subsection{Comparación de los resultados por clase de los modelos de clasificación multiclase}

A pesar de que el modelo 4º-MCM98 no supera al de \textit{Sarhan et al.} en clases como \textit{Exploits} y \textit{Generic}, presenta un desempeño significativamente superior en \textit{Analysis} y \textit{Worms}. Estas diferencias que se pueden observar en la Tabla \ref{tab:compmulclass} pueden estar relacionadas con el preprocesamiento, la selección de características y la estrategia de balanceo utilizada mencionadas en el Capítulo \ref{cap.modelos}.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Clase} & \textbf{\textit{F1-Score} (\textit{Sarhan et al.})} & \textbf{\textit{F1-Score} (4º-MCM98)} \\
\hline
Analysis (0) & 0.15 & 0.97 \\
Backdoor (1) & 0.17 & 0.20 \\
DoS (2) & 0.41 & 0.25 \\
Exploits (3) & 0.82 & 0.48 \\
Fuzzers (4) & 0.55 & 0.75 \\
Generic (5) & 0.66 & 0.28 \\
Reconnaissance (6) & 0.82 & 0.56 \\
Shellcode (7) & 0.75 & 0.72 \\
Worms (8) & 0.55 & 0.92 \\
\hline
\end{tabular}
\caption{Comparación de los valores obtenidos en \textit{F1-Score} por clase.}
\label{tab:compmulclass}
\end{table}


\subsection{Evaluación comparativa del rendimiento}
Tras observar las diferencias entre los valores de las métricas obtenidas en ambos proyectos, se puede asumir que:

\begin{itemize}
    \item El modelo 3º-MCB98 supera de forma consistente al modelo propuesto por \textit{Sarhan et al.} en todas las métricas evaluadas para la tarea de clasificación binaria.
  \item El modelo 4º-MCM98 destaca en clases con un menor número de muestras en el conjunto de datos utilizado para el entrenamiento como \textit{Analysis} y \textit{Worms}, mientras que el modelo de \textit{Sarhan et al.} muestra mayor estabilidad en clases con una mayor población de muestras. Esta diferencia puede deberse al uso de la función de pérdida ajustada utilizada en los modelos desarrollados en este proyecto, que penaliza con mayor severidad los errores en clases poco representadas, tal como se discute a lo largo del presente trabajo.
  
\end{itemize}


Los modelos desarrollados en este trabajo presentan mejoras notables en la clasificación binaria y un rendimiento competitivo en la clasificación multiclase. Aunque persisten desafíos en clases como \textit{Generic} y \textit{Exploits}, los resultados alcanzados en clases con relaciones de datos más complejas sugieren una mayor capacidad de generalización frente a los modelos publicados previamente.